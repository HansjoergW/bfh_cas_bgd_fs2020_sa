---

title: 01_02_Join_SEC_Data

keywords: fastai
sidebar: home_sidebar



---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_02_Join_SEC_Data.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This notebook contains the code to join the attributs from the thre files "num.txt", "sub.txt", and "pre.txt" together into one single CSV-file which can then be used for further processing.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># imports</span>
<span class="kn">from</span> <span class="nn">bfh_cas_bgd_fs2020_sa.core</span> <span class="kn">import</span> <span class="o">*</span> <span class="c1"># initialze spark</span>

<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Set</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.dataframe</span> <span class="kn">import</span> <span class="n">DataFrame</span>

<span class="kn">import</span> <span class="nn">shutil</span>          <span class="c1"># provides high level file operations</span>
<span class="kn">import</span> <span class="nn">time</span>            <span class="c1"># used to measure execution time</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># basic definitions</span>
<span class="n">zip_folder</span> <span class="o">=</span> <span class="s2">&quot;./data/&quot;</span> 
<span class="n">zip_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">zip_folder</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Init-Spark">Init Spark<a class="anchor-link" href="#Init-Spark"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># init Spark</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">get_spark_session</span><span class="p">()</span> <span class="c1"># Session anlegen</span>
<span class="n">spark</span> <span class="c1"># display the moste important information of the session</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

            <div>
                <p><b>SparkSession - in-memory</b></p>
                
        <div>
            <p><b>SparkContext</b></p>

            <p><a href="http://192.168.0.163:4040">Spark UI</a></p>

            <dl>
              <dt>Version</dt>
                <dd><code>v2.4.5</code></dd>
              <dt>Master</dt>
                <dd><code>local[*]</code></dd>
              <dt>AppName</dt>
                <dd><code>default</code></dd>
            </dl>
        </div>
        
            </div>
        
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Create-Zip-Files-dataframe">Create Zip-Files dataframe<a class="anchor-link" href="#Create-Zip-Files-dataframe"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">zip_files</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">file</span><span class="p">)</span> <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">zip_path</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*.zip&quot;</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># convert the list into a Spark dataframe</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>

<span class="n">zip_files_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">zip_files</span><span class="p">,</span> <span class="n">StringType</span><span class="p">())</span>
<span class="n">zip_files_df</span> <span class="o">=</span> <span class="n">zip_files_df</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span><span class="s2">&quot;url&quot;</span><span class="p">)</span>
<span class="n">zip_files_df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>root
 |-- url: string (nullable = true)

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Read-file-inside-zip-and-convert-it-to-a-spark-dataframe">Read file inside zip and convert it to a spark dataframe<a class="anchor-link" href="#Read-file-inside-zip-and-convert-it-to-a-spark-dataframe"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Define constants for the names of the filese inside the zip file</span>
<span class="n">SUB_TXT</span> <span class="o">=</span> <span class="s2">&quot;sub.txt&quot;</span>
<span class="n">PRE_TXT</span> <span class="o">=</span> <span class="s2">&quot;pre.txt&quot;</span>
<span class="n">NUM_TXT</span> <span class="o">=</span> <span class="s2">&quot;num.txt&quot;</span>
<span class="n">TAG_TXT</span> <span class="o">=</span> <span class="s2">&quot;tag.txt&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I was looking for a way to directly read the content from csv.file inside a zip file into a spark dataframe. But after spending some time researching, i wasn't able to find a way to do it directly.<br>
Since that doesn't seem possible, we need to find other solutions and compare them.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Baseline--&gt;-loading-an-extracted-num.txt-directly-into-a-Spark-dataframe">Baseline -&gt; loading an extracted num.txt directly into a Spark dataframe<a class="anchor-link" href="#Baseline--&gt;-loading-an-extracted-num.txt-directly-into-a-Spark-dataframe"> </a></h3><p>In order to compare the performance of loading csv data into a spark_dataframe we should have a baseline value.<br>
We will load the extracted num.txt file from 2019q3 and see how long it will take.
Note, the num.txt has to be extracted into the folder "tmp/2019q3/"</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">df_test_num</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s1">&#39;tmp/2019q3/num.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_test_num</span><span class="o">.</span><span class="n">count</span><span class="p">())</span> <span class="c1"># we need to execute an action, otherwise only the graph is created</span>
<span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;duration: &quot;</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2325267
duration:  0.8069617748260498
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df_test_num</span><span class="o">.</span><span class="n">first</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Row(adsh=&#39;0001625376-19-000017&#39;, tag=&#39;EntityPublicFloat&#39;, version=&#39;dei/2014&#39;, coreg=None, ddate=&#39;20180430&#39;, qtrs=&#39;0&#39;, uom=&#39;USD&#39;, value=&#39;0.0000&#39;, footnote=None)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The result is pretty reasonable. It took less than a second to load and parse the file into a spark dataframe. (we have to keep in mind, that the disk very likely caches this file after the first load)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Extract-file-from-zip-and-load-it-with-spark.csv.read">Extract file from zip and load it with spark.csv.read<a class="anchor-link" href="#Extract-file-from-zip-and-load-it-with-spark.csv.read"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One solution could be to extract the content and write it as a temporary file and then load that file into a spark dataframe. We cannot use a temporary file (tempfile.TemporaryFile()), since spark will try to access it from another process which is not possible for a temporary file</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tempfile</span>

<span class="n">test_zip</span> <span class="o">=</span> <span class="n">zip_files</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">test_zip</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">container_zip</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">container_zip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">NUM_TXT</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;./tmp/tempfile.xt&quot;</span><span class="p">,</span> <span class="s2">&quot;wb+&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">fp</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">df_test_num</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">df_test_num</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;duration: &quot;</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2325267
duration:  2.333956718444824
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As expected, it takes a little longer, but it is still a very good result.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Load-data-into-tuples-and-create-spark-dataframe-from-tuple">Load data into tuples and create spark dataframe from tuple<a class="anchor-link" href="#Load-data-into-tuples-and-create-spark-dataframe-from-tuple"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another solution is to load the data into a list of tuples and then use that list of tuples to create the spark dataframe. This is code a wrote a few months ago, slightly adapted.<br>
This code is not suitable for CSV files containing real text columns, because no escaping is checked.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">clear_empty_fields</span><span class="p">(</span><span class="n">row</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span><span class="kc">None</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot; This helper method makes sure, that empty entries are converted to None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">entry</span> <span class="k">if</span> <span class="n">entry</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">row</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_file_data</span><span class="p">(</span><span class="n">zip_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">data_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]:</span>
    <span class="sd">&quot;&quot;&quot; This function extracts the file with the name provided in data_file from a zipfile which name is provided in zip_file.</span>
<span class="sd">        It then parses the file and returns a list of all tuples.</span>
<span class="sd">        The function assumes, that there is a header row and that the columns are separated by a \t.</span>
<span class="sd">        Furthermore, it assumes that no string escaping has to be done.</span>
<span class="sd">        </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">zip_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">container_zip</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">container_zip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>

            <span class="n">tuple_lines</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
                    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
                    <span class="n">line</span> <span class="o">=</span> <span class="n">clear_empty_fields</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">))</span>
                    <span class="n">tuple_lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
                    <span class="c1"># sometimes there were encoding problems when storing to windows fs. if utf8 failed, trying to read as</span>
                    <span class="c1"># as windows-1252 helped in these cases</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;windows-1252&quot;</span><span class="p">)</span>
                        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
                        <span class="n">line</span> <span class="o">=</span> <span class="n">clear_empty_fields</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">))</span>
                        <span class="n">tuple_lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">ex</span><span class="p">),</span> <span class="s2">&quot;   &quot;</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">tuple_lines</span><span class="p">[:</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]),</span> <span class="n">tuple_lines</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="c1"># skip the header row, since we know that all files that we read have a header row</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In order to test the code above and to have feeling for the performance, we measure the time that is needed to load the num.txt file directly from the zip file and convert it into a list of tuples.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># A short check to see if the reading works</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">headers</span><span class="p">,</span> <span class="n">list_of_tuples</span> <span class="o">=</span> <span class="n">get_file_data</span><span class="p">(</span><span class="n">zip_files</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">NUM_TXT</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">headers</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="s2">&quot;:&quot;</span><span class="p">,</span> <span class="n">list_of_tuples</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;duration: &quot;</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>adsh : 0000034563-19-000064
duration:  8.604996681213379
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It takes about 9 seconds. <br>
Just creating the list with tuples is already much slower than extracting the file and using spark.read.csv. Lets check how long the creation of a spark dataframe out of the tuple will take.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">headers</span><span class="p">,</span> <span class="n">list_of_tuples</span> <span class="o">=</span> <span class="n">get_file_data</span><span class="p">(</span><span class="n">zip_files</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">NUM_TXT</span><span class="p">)</span>
<span class="n">df_tuple</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">list_of_tuples</span> <span class="p">,</span> <span class="n">headers</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_tuple</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;duration: &quot;</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2325267
duration:  132.30002903938293
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It takes over 2 minutes. Of course, it maybe that there are better ways to do it, but since the performance of reading directly from a file performs way better, it doesn't make sense to try to follow this approach</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-spark.read.csv-with-RDD-parallelize">Using spark.read.csv with RDD parallelize<a class="anchor-link" href="#Using-spark.read.csv-with-RDD-parallelize"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="n">StringIO</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">test_zip</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">container_zip</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">container_zip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">NUM_TXT</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
        <span class="n">df_test_num</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">lines</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">df_test_num</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>        
<span class="n">duration</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;duration: &quot;</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2325267
duration:  13.77500033378601
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_test_num</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;adsh&#39;,
 &#39;tag&#39;,
 &#39;version&#39;,
 &#39;coreg&#39;,
 &#39;ddate&#39;,
 &#39;qtrs&#39;,
 &#39;uom&#39;,
 &#39;value&#39;,
 &#39;footnote&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It takeslonger than loading the file directly. But it would be a very easy to implement.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion"> </a></h3><p>Since this is mainly a ontime operation, i will use the "Using spark.read.csv with RDD parallelize" as a first approach. If that shouldn't work out well, i would go for the extract and save to disk approach.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="DF-Reader-implementation">DF Reader implementation<a class="anchor-link" href="#DF-Reader-implementation"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">read_csv_in_zip_into_df</span><span class="p">(</span><span class="n">zip_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">data_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataFrame</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">test_zip</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">container_zip</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">container_zip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">NUM_TXT</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span><span class="n">lines</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Joining-the-data-into-one-spark-dataframe">Joining the data into one spark dataframe<a class="anchor-link" href="#Joining-the-data-into-one-spark-dataframe"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># this takes some time till loaded</span>
<span class="c1"># lap1:  2.0500004291534424</span>
<span class="c1"># lap2:  66.70102596282959</span>
<span class="c1"># lap2:  133.26235961914062 -&gt; loading the data and creating a tuple is only about 8 seconds... so about 2 minutes are needed to create the df from the tuple</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">df_sub</span> <span class="o">=</span> <span class="n">read_csv_in_zip_into_df</span><span class="p">(</span><span class="n">zip_files</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">SUB_TXT</span><span class="p">)</span>
<span class="n">lap1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">lap1_time</span> <span class="o">=</span> <span class="n">lap1</span><span class="o">-</span><span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lap1: &quot;</span><span class="p">,</span> <span class="n">lap1_time</span><span class="p">)</span>
<span class="n">df_pre</span> <span class="o">=</span> <span class="n">read_csv_in_zip_into_df</span><span class="p">(</span><span class="n">zip_files</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">PRE_TXT</span><span class="p">)</span>
<span class="n">lap2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">lap2_time</span> <span class="o">=</span> <span class="n">lap2</span><span class="o">-</span><span class="n">lap1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lap2: &quot;</span><span class="p">,</span> <span class="n">lap2_time</span><span class="p">)</span>
<span class="n">df_num</span> <span class="o">=</span> <span class="n">read_csv_in_zip_into_df</span><span class="p">(</span><span class="n">zip_files</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">NUM_TXT</span><span class="p">)</span>
<span class="n">lap3</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">lap3_time</span> <span class="o">=</span> <span class="n">lap3</span><span class="o">-</span><span class="n">lap2</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lap2: &quot;</span><span class="p">,</span> <span class="n">lap3_time</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>lap1:  2.0500004291534424
lap2:  66.70102596282959
lap2:  133.26235961914062
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># this join produces a df with two duplicated columns named adsh</span>
<span class="c1"># that should be prevented: https://kb.databricks.com/data/join-two-dataframes-duplicated-columns.html</span>
<span class="n">df_join1</span> <span class="o">=</span> <span class="n">df_num</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_sub</span><span class="p">,</span> <span class="n">df_num</span><span class="o">.</span><span class="n">adsh</span> <span class="o">==</span> <span class="n">df_sub</span><span class="o">.</span><span class="n">adsh</span><span class="p">)</span>
<span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_join1</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s2">&quot;adsh&quot;</span><span class="p">]</span> <span class="c1"># shows that the column adsh is twice in the dataframe</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;adsh&#39;, &#39;adsh&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># correct way of joining using a list with the column names</span>
<span class="n">df_join1</span> <span class="o">=</span> <span class="n">df_num</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_sub</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;adsh&quot;</span><span class="p">])</span>
<span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df_join1</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s2">&quot;adsh&quot;</span><span class="p">]</span> <span class="c1"># shows that the column adsh appears now only once in the df</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;adsh&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># joining the dataframes together</span>
<span class="n">df_joined</span> <span class="o">=</span> <span class="n">df_num</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_sub</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;adsh&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_pre</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;adsh&quot;</span><span class="p">,</span><span class="s2">&quot;version&quot;</span><span class="p">,</span><span class="s2">&quot;tag&quot;</span><span class="p">],</span><span class="s2">&quot;left&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_joined</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="c1"># this will start the whole DAG and executes the join</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>2570409</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">zip_files</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;data\\2019q3.zip&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

