---

title: Parquet

keywords: fastai
sidebar: home_sidebar



---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_parquet.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># common imports</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">bfh_cas_bgd_fs2020_sa.core</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Check the current working dir</span>
<span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>C:\ieu\projects\bfh_cas_bgd_fs2020_sa
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Basic Definition</span>
<span class="n">data_folder</span> <span class="o">=</span> <span class="s2">&quot;./data/&quot;</span> <span class="c1"># folder with testdata</span>
<span class="n">temp_folder</span> <span class="o">=</span> <span class="s2">&quot;./tmp/&quot;</span>
<span class="n">parquet_folder</span> <span class="o">=</span> <span class="s2">&quot;./parquet/&quot;</span>
<span class="n">data_files</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;2019q3.zip&#39;</span><span class="p">,</span><span class="s1">&#39;2019q4.zip&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Init-Spark">Init Spark<a class="anchor-link" href="#Init-Spark"> </a></h2><blockquote><p>This code initialises the SparkSession and therefore the SparkContext. Pressing the link "Spark UI" opens the Spark UI for this session.</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># init Spark</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">get_spark_session</span><span class="p">()</span> <span class="c1"># Session anlegen</span>
<span class="n">spark</span> <span class="c1"># display the moste important information of the session</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)
Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1145, in send_command
    self.socket.sendall(command.encode(&#34;utf-8&#34;))
ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 985, in send_command
    response = connection.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1149, in send_command
    &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 3343, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &#34;&lt;ipython-input-82-6174a0f27226&gt;&#34;, line 2, in &lt;module&gt;
    spark = get_spark_session() # Session anlegen
  File &#34;C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py&#34;, line 15, in get_spark_session
    return SparkSession.builder.appName(appname).getOrCreate()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py&#34;, line 183, in getOrCreate
    session._jsparkSession.sessionState().conf().setConfString(key, value)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1255, in __call__
    answer = self.gateway_client.send_command(command)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1000, in send_command
    response = self.send_command(command, binary=binary)
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 983, in send_command
    connection = self._get_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 931, in _get_connection
    connection = self._create_connection()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 937, in _create_connection
    connection.start()
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1079, in start
    raise Py4JNetworkError(msg, e)
py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\IPython\core\interactiveshell.py&#34;, line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: &#39;Py4JNetworkError&#39; object has no attribute &#39;_render_traceback_&#39;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 929, in _get_connection
    connection = self.deque.pop()
IndexError: pop from an empty deque

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File &#34;C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py&#34;, line 1067, in start
    self.socket.connect((self.address, self.port))
ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">ConnectionResetError</span>                      Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">send_command</span><span class="ansi-blue-intense-fg ansi-bold">(self, command)</span>
<span class="ansi-green-fg">   1144</span>             <span class="ansi-red-intense-fg ansi-bold"># if it sent a RST packet (SO_LINGER)</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1145</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>socket<span class="ansi-yellow-intense-fg ansi-bold">.</span>sendall<span class="ansi-yellow-intense-fg ansi-bold">(</span>command<span class="ansi-yellow-intense-fg ansi-bold">.</span>encode<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-blue-intense-fg ansi-bold">&#34;utf-8&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1146</span>         <span class="ansi-green-intense-fg ansi-bold">except</span> Exception <span class="ansi-green-intense-fg ansi-bold">as</span> e<span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-red-intense-fg ansi-bold">ConnectionResetError</span>: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen

During handling of the above exception, another exception occurred:

<span class="ansi-red-intense-fg ansi-bold">Py4JNetworkError</span>                          Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">send_command</span><span class="ansi-blue-intense-fg ansi-bold">(self, command, retry, binary)</span>
<span class="ansi-green-fg">    984</span>         <span class="ansi-green-intense-fg ansi-bold">try</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 985</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>response <span class="ansi-yellow-intense-fg ansi-bold">=</span> connection<span class="ansi-yellow-intense-fg ansi-bold">.</span>send_command<span class="ansi-yellow-intense-fg ansi-bold">(</span>command<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    986</span>             <span class="ansi-green-intense-fg ansi-bold">if</span> binary<span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">send_command</span><span class="ansi-blue-intense-fg ansi-bold">(self, command)</span>
<span class="ansi-green-fg">   1148</span>             raise Py4JNetworkError(
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1149</span><span class="ansi-yellow-intense-fg ansi-bold">                 &#34;Error while sending&#34;, e, proto.ERROR_ON_SEND)
</span><span class="ansi-green-fg">   1150</span> 

<span class="ansi-red-intense-fg ansi-bold">Py4JNetworkError</span>: Error while sending

During handling of the above exception, another exception occurred:

<span class="ansi-red-intense-fg ansi-bold">IndexError</span>                                Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">_get_connection</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    928</span>         <span class="ansi-green-intense-fg ansi-bold">try</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 929</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>connection <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>deque<span class="ansi-yellow-intense-fg ansi-bold">.</span>pop<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    930</span>         <span class="ansi-green-intense-fg ansi-bold">except</span> IndexError<span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-red-intense-fg ansi-bold">IndexError</span>: pop from an empty deque

During handling of the above exception, another exception occurred:

<span class="ansi-red-intense-fg ansi-bold">ConnectionRefusedError</span>                    Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">start</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">   1066</span>         <span class="ansi-green-intense-fg ansi-bold">try</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1067</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>socket<span class="ansi-yellow-intense-fg ansi-bold">.</span>connect<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>address<span class="ansi-yellow-intense-fg ansi-bold">,</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>port<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1068</span>             self<span class="ansi-yellow-intense-fg ansi-bold">.</span>stream <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>socket<span class="ansi-yellow-intense-fg ansi-bold">.</span>makefile<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-blue-intense-fg ansi-bold">&#34;rb&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-red-intense-fg ansi-bold">ConnectionRefusedError</span>: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte

During handling of the above exception, another exception occurred:

<span class="ansi-red-intense-fg ansi-bold">Py4JNetworkError</span>                          Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-82-6174a0f27226&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">      1</span> <span class="ansi-red-intense-fg ansi-bold"># init Spark</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 2</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>spark <span class="ansi-yellow-intense-fg ansi-bold">=</span> get_spark_session<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span> <span class="ansi-red-intense-fg ansi-bold"># Session anlegen</span>
<span class="ansi-green-fg">      3</span> spark <span class="ansi-red-intense-fg ansi-bold"># display the moste important information of the session</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\projects\bfh_cas_bgd_fs2020_sa\bfh_cas_bgd_fs2020_sa\core.py</span> in <span class="ansi-cyan-fg">get_spark_session</span><span class="ansi-blue-intense-fg ansi-bold">(appname)</span>
<span class="ansi-green-fg">     13</span>     &#34;&#34;&#34;
<span class="ansi-green-fg">     14</span>     findspark<span class="ansi-yellow-intense-fg ansi-bold">.</span>init<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">---&gt; 15</span><span class="ansi-yellow-intense-fg ansi-bold">     </span><span class="ansi-green-intense-fg ansi-bold">return</span> SparkSession<span class="ansi-yellow-intense-fg ansi-bold">.</span>builder<span class="ansi-yellow-intense-fg ansi-bold">.</span>appName<span class="ansi-yellow-intense-fg ansi-bold">(</span>appname<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">.</span>getOrCreate<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     16</span> 
<span class="ansi-green-fg">     17</span> <span class="ansi-red-intense-fg ansi-bold"># Cell</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\session.py</span> in <span class="ansi-cyan-fg">getOrCreate</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    181</span>                     session <span class="ansi-yellow-intense-fg ansi-bold">=</span> SparkSession<span class="ansi-yellow-intense-fg ansi-bold">(</span>sc<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    182</span>                 <span class="ansi-green-intense-fg ansi-bold">for</span> key<span class="ansi-yellow-intense-fg ansi-bold">,</span> value <span class="ansi-green-intense-fg ansi-bold">in</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_options<span class="ansi-yellow-intense-fg ansi-bold">.</span>items<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 183</span><span class="ansi-yellow-intense-fg ansi-bold">                     </span>session<span class="ansi-yellow-intense-fg ansi-bold">.</span>_jsparkSession<span class="ansi-yellow-intense-fg ansi-bold">.</span>sessionState<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">.</span>conf<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">.</span>setConfString<span class="ansi-yellow-intense-fg ansi-bold">(</span>key<span class="ansi-yellow-intense-fg ansi-bold">,</span> value<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    184</span>                 <span class="ansi-green-intense-fg ansi-bold">for</span> key<span class="ansi-yellow-intense-fg ansi-bold">,</span> value <span class="ansi-green-intense-fg ansi-bold">in</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_options<span class="ansi-yellow-intense-fg ansi-bold">.</span>items<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    185</span>                     session<span class="ansi-yellow-intense-fg ansi-bold">.</span>sparkContext<span class="ansi-yellow-intense-fg ansi-bold">.</span>_conf<span class="ansi-yellow-intense-fg ansi-bold">.</span>set<span class="ansi-yellow-intense-fg ansi-bold">(</span>key<span class="ansi-yellow-intense-fg ansi-bold">,</span> value<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-intense-fg ansi-bold">(self, *args)</span>
<span class="ansi-green-fg">   1253</span>             proto<span class="ansi-yellow-intense-fg ansi-bold">.</span>END_COMMAND_PART
<span class="ansi-green-fg">   1254</span> 
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1255</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>answer <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>gateway_client<span class="ansi-yellow-intense-fg ansi-bold">.</span>send_command<span class="ansi-yellow-intense-fg ansi-bold">(</span>command<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1256</span>         return_value = get_return_value(
<span class="ansi-green-fg">   1257</span>             answer, self.gateway_client, self.target_id, self.name)

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">send_command</span><span class="ansi-blue-intense-fg ansi-bold">(self, command, retry, binary)</span>
<span class="ansi-green-fg">    998</span>             <span class="ansi-green-intense-fg ansi-bold">if</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_should_retry<span class="ansi-yellow-intense-fg ansi-bold">(</span>retry<span class="ansi-yellow-intense-fg ansi-bold">,</span> connection<span class="ansi-yellow-intense-fg ansi-bold">,</span> pne<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    999</span>                 logging<span class="ansi-yellow-intense-fg ansi-bold">.</span>info<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-blue-intense-fg ansi-bold">&#34;Exception while sending command.&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> exc_info<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-green-intense-fg ansi-bold">True</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1000</span><span class="ansi-yellow-intense-fg ansi-bold">                 </span>response <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>send_command<span class="ansi-yellow-intense-fg ansi-bold">(</span>command<span class="ansi-yellow-intense-fg ansi-bold">,</span> binary<span class="ansi-yellow-intense-fg ansi-bold">=</span>binary<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1001</span>             <span class="ansi-green-intense-fg ansi-bold">else</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">   1002</span>                 logging.exception(

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">send_command</span><span class="ansi-blue-intense-fg ansi-bold">(self, command, retry, binary)</span>
<span class="ansi-green-fg">    981</span>          <span class="ansi-green-intense-fg ansi-bold">if</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">`</span>binary<span class="ansi-red-fg">`</span> <span class="ansi-green-intense-fg ansi-bold">is</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">`</span><span class="ansi-green-intense-fg ansi-bold">True</span><span class="ansi-red-fg">`</span><span class="ansi-yellow-intense-fg ansi-bold">.</span>
<span class="ansi-green-fg">    982</span>         &#34;&#34;&#34;
<span class="ansi-green-intense-fg ansi-bold">--&gt; 983</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>connection <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_get_connection<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    984</span>         <span class="ansi-green-intense-fg ansi-bold">try</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    985</span>             response <span class="ansi-yellow-intense-fg ansi-bold">=</span> connection<span class="ansi-yellow-intense-fg ansi-bold">.</span>send_command<span class="ansi-yellow-intense-fg ansi-bold">(</span>command<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">_get_connection</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    929</span>             connection <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>deque<span class="ansi-yellow-intense-fg ansi-bold">.</span>pop<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    930</span>         <span class="ansi-green-intense-fg ansi-bold">except</span> IndexError<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 931</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>connection <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_create_connection<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    932</span>         <span class="ansi-green-intense-fg ansi-bold">return</span> connection
<span class="ansi-green-fg">    933</span> 

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">_create_connection</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    935</span>         connection = GatewayConnection(
<span class="ansi-green-fg">    936</span>             self.gateway_parameters, self.gateway_property)
<span class="ansi-green-intense-fg ansi-bold">--&gt; 937</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>connection<span class="ansi-yellow-intense-fg ansi-bold">.</span>start<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    938</span>         <span class="ansi-green-intense-fg ansi-bold">return</span> connection
<span class="ansi-green-fg">    939</span> 

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">start</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">   1077</span>                 <span class="ansi-blue-intense-fg ansi-bold">&#34;server ({0}:{1})&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">.</span>format<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>address<span class="ansi-yellow-intense-fg ansi-bold">,</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>port<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1078</span>             logger<span class="ansi-yellow-intense-fg ansi-bold">.</span>exception<span class="ansi-yellow-intense-fg ansi-bold">(</span>msg<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1079</span><span class="ansi-yellow-intense-fg ansi-bold">             </span><span class="ansi-green-intense-fg ansi-bold">raise</span> Py4JNetworkError<span class="ansi-yellow-intense-fg ansi-bold">(</span>msg<span class="ansi-yellow-intense-fg ansi-bold">,</span> e<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1080</span> 
<span class="ansi-green-fg">   1081</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> _authenticate_connection<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-red-intense-fg ansi-bold">Py4JNetworkError</span>: An error occurred while trying to connect to the Java server (127.0.0.1:62782)</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Datafiles">Datafiles<a class="anchor-link" href="#Datafiles"> </a></h2><blockquote><p>The directory contains two zipfiles (2019q3.zip, 2019q4.zip). Each of them contains 4 csv files. The columns and the relation between these files are described in the readme.htm.
Each zip file contains all quarterly and yearly reports that were filled during the quarter denoted by the filename.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Working-with-the-data">Working with the data<a class="anchor-link" href="#Working-with-the-data"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Unpacking">Unpacking<a class="anchor-link" href="#Unpacking"> </a></h3><blockquote><p>In a first step, the content of the files are unzipped and placed in separated folders</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">data_file</span> <span class="ow">in</span> <span class="n">data_files</span><span class="p">:</span>
    <span class="n">path_to_zip_file</span> <span class="o">=</span> <span class="n">data_folder</span> <span class="o">+</span> <span class="n">data_file</span>
    <span class="n">directory_to_extract_to</span> <span class="o">=</span> <span class="n">temp_folder</span> <span class="o">+</span> <span class="n">data_file</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">path_to_zip_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
        <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">directory_to_extract_to</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>the sizes of the directories</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Data folder: &#39;</span><span class="p">,</span> <span class="n">get_size_format</span><span class="p">(</span><span class="n">get_directory_size</span><span class="p">(</span><span class="n">data_folder</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Temp folder: &#39;</span><span class="p">,</span> <span class="n">get_size_format</span><span class="p">(</span><span class="n">get_directory_size</span><span class="p">(</span><span class="n">temp_folder</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Data folder:  76.58MB
Temp folder:  748.04MB
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-Parquet">Using Parquet<a class="anchor-link" href="#Using-Parquet"> </a></h3><blockquote><p>let us read a csv file and store it as a parquet file</p>
<ul>
<li>API doc of the csv reader:<a href="https://spark.apache.org/docs/2.4.5/api/python/pyspark.sql.html?highlight=parquet#pyspark.sql.DataFrameReader.csv&gt;">https://spark.apache.org/docs/2.4.5/api/python/pyspark.sql.html?highlight=parquet#pyspark.sql.DataFrameReader.csv&gt;</a> * API doc of the parquet writer:<a href="https://spark.apache.org/docs/2.4.5/api/python/pyspark.sql.html?highlight=parquet#pyspark.sql.DataFrameWriter.parquet">https://spark.apache.org/docs/2.4.5/api/python/pyspark.sql.html?highlight=parquet#pyspark.sql.DataFrameWriter.parquet</a></li>
</ul>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># imports that are used in this section</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">DateType</span><span class="p">,</span> <span class="n">DoubleType</span><span class="p">,</span> <span class="n">IntegerType</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># as a test csv file, &quot;num.txt&quot; from the folder 2019q3 is used</span>
<span class="n">test_file</span> <span class="o">=</span> <span class="n">temp_folder</span> <span class="o">+</span> <span class="s1">&#39;2019q3/num.txt&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;size of test file: &#39;</span><span class="p">,</span> <span class="n">get_size_format</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">test_file</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>size of test file:  236.70MB
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Reading-a-CSV-file">Reading a CSV file<a class="anchor-link" href="#Reading-a-CSV-file"> </a></h4><blockquote><p>As a first step, the csv file has to be loaded into a spark df. 
The file has a header row and the columns are separated by a TAB (\t).</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_test_num</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">test_file</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>When checking the format in the next cell, we see that all columns were read as a string. That is ok for most of the columns but when checking the definitions for the num.txt file in the readme.htm we see, that ddate is a date in the format 'yyyymmdd', qtrs and coreg are 'int' and value is a float.</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;first row: &#39;</span><span class="p">,</span> <span class="n">df_test_num</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;count     :&#39;</span><span class="p">,</span> <span class="n">df_test_num</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="n">df_test_num</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>first row:  [Row(adsh=&#39;0001625376-19-000017&#39;, tag=&#39;EntityPublicFloat&#39;, version=&#39;dei/2014&#39;, coreg=None, ddate=datetime.date(2018, 4, 30), qtrs=0, uom=&#39;USD&#39;, value=0.0, footnote=None)]
count     : 2325267
root
 |-- adsh: string (nullable = true)
 |-- tag: string (nullable = true)
 |-- version: string (nullable = true)
 |-- coreg: integer (nullable = true)
 |-- ddate: date (nullable = true)
 |-- qtrs: integer (nullable = true)
 |-- uom: string (nullable = true)
 |-- value: double (nullable = true)
 |-- footnote: string (nullable = true)

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>Acutally, spark can try to infer the types of the columns from the data itself, so lets try that by using the "inferSchema" option</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df_test_num</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">test_file</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>As we can see in the next cell, we were only partially sucessfull. The reader was able to detect that qtrs is an integer and that value is a double. But it failed to recognize that ddate is actually a date and that coreg should be an int. That was to be expected:ddate looks like int and the coreg field is only used in special situations, so there is a good change that its field is None for all entries in the file. It looks as if we have to define the schema by hand</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df_test_num</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">df_test_num</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[Row(adsh=&#39;0001625376-19-000017&#39;, tag=&#39;EntityPublicFloat&#39;, version=&#39;dei/2014&#39;, coreg=None, ddate=20180430, qtrs=0, uom=&#39;USD&#39;, value=0.0, footnote=None)]
root
 |-- adsh: string (nullable = true)
 |-- tag: string (nullable = true)
 |-- version: string (nullable = true)
 |-- coreg: string (nullable = true)
 |-- ddate: integer (nullable = true)
 |-- qtrs: integer (nullable = true)
 |-- uom: string (nullable = true)
 |-- value: double (nullable = true)
 |-- footnote: string (nullable = true)

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>All necessary classes to define a schema are located inside the package pyspark.sql.types and for our example we need the following import
from pyspark.sql.types import StructType, StructField, StringType, DateType, DoubleType, IntegerType</p>
<p>An important point is that the dateFormat has to be defined as parameter when calling spark.read.csv()</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span><span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;adsh&quot;</span><span class="p">,</span>    <span class="n">StringType</span><span class="p">(),</span>  <span class="kc">True</span><span class="p">),</span>\
                     <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;tag&quot;</span><span class="p">,</span>     <span class="n">StringType</span><span class="p">(),</span>  <span class="kc">True</span><span class="p">),</span>\
                     <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;version&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span>  <span class="kc">True</span><span class="p">),</span>\
                     <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;coreg&quot;</span><span class="p">,</span>   <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>\
                     <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;ddate&quot;</span><span class="p">,</span>   <span class="n">DateType</span><span class="p">(),</span>    <span class="kc">True</span><span class="p">),</span>\
                     <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;qtrs&quot;</span><span class="p">,</span>    <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>\
                     <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;uom&quot;</span><span class="p">,</span>     <span class="n">StringType</span><span class="p">(),</span>  <span class="kc">True</span><span class="p">),</span>\
                     <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span>   <span class="n">DoubleType</span><span class="p">(),</span>  <span class="kc">True</span><span class="p">),</span>\
                     <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;footnote&quot;</span><span class="p">,</span><span class="n">StringType</span><span class="p">(),</span>  <span class="kc">True</span><span class="p">)</span>\
                    <span class="p">])</span>
<span class="n">df_test_num</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">test_file</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dateFormat</span><span class="o">=</span><span class="s2">&quot;yyyyMMdd&quot;</span><span class="p">,</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df_test_num</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">df_test_num</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[Row(adsh=&#39;0001625376-19-000017&#39;, tag=&#39;EntityPublicFloat&#39;, version=&#39;dei/2014&#39;, coreg=None, ddate=datetime.date(2018, 4, 30), qtrs=0, uom=&#39;USD&#39;, value=0.0, footnote=None)]
root
 |-- adsh: string (nullable = true)
 |-- tag: string (nullable = true)
 |-- version: string (nullable = true)
 |-- coreg: integer (nullable = true)
 |-- ddate: date (nullable = true)
 |-- qtrs: integer (nullable = true)
 |-- uom: string (nullable = true)
 |-- value: double (nullable = true)
 |-- footnote: string (nullable = true)

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="simple-write-as-Parquet">simple write as Parquet<a class="anchor-link" href="#simple-write-as-Parquet"> </a></h4><blockquote><p>As first version the dataframe is stored directly in parquet format without additional options</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">parquet_folder_pure</span> <span class="o">=</span> <span class="n">parquet_folder</span><span class="o">+</span><span class="s2">&quot;pure/&quot;</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">parquet_folder_pure</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span> <span class="c1"># mode &#39;overwrite&#39; overwrites the data, if they are already present</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;size of parquet_folder_pure: &#39;</span><span class="p">,</span> <span class="n">get_size_format</span><span class="p">(</span><span class="n">get_directory_size</span><span class="p">(</span><span class="n">parquet_folder_pure</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>size of parquet_folder_pure:  22.78MB
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>Parquet was able to compress the data down to 10% of the orginal size.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="using-partitions">using partitions<a class="anchor-link" href="#using-partitions"> </a></h4><blockquote><p>Parquet can also store the data in different partitions wich will create a new directory for every partition.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>in a first test we will partition by the "adsh" column which is the identifier for the different reports</p>
</blockquote>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">parquet_folder_by_adsh</span> <span class="o">=</span> <span class="n">parquet_folder</span><span class="o">+</span><span class="s2">&quot;byadsh/&quot;</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">partitionBy</span><span class="p">(</span><span class="s1">&#39;adsh&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">parquet_folder_by_adsh</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;overwrite&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">Py4JJavaError</span>                             Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-76-33991c22aa44&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">      1</span> parquet_folder_by_adsh <span class="ansi-yellow-intense-fg ansi-bold">=</span> parquet_folder<span class="ansi-yellow-intense-fg ansi-bold">+</span><span class="ansi-blue-intense-fg ansi-bold">&#34;byadsh/&#34;</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 2</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>df<span class="ansi-yellow-intense-fg ansi-bold">.</span>write<span class="ansi-yellow-intense-fg ansi-bold">.</span>partitionBy<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-blue-intense-fg ansi-bold">&#39;adsh&#39;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">.</span>parquet<span class="ansi-yellow-intense-fg ansi-bold">(</span>parquet_folder_by_adsh<span class="ansi-yellow-intense-fg ansi-bold">,</span> mode<span class="ansi-yellow-intense-fg ansi-bold">=</span><span class="ansi-blue-intense-fg ansi-bold">&#34;overwrite&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\readwriter.py</span> in <span class="ansi-cyan-fg">parquet</span><span class="ansi-blue-intense-fg ansi-bold">(self, path, mode, partitionBy, compression)</span>
<span class="ansi-green-fg">    842</span>             self<span class="ansi-yellow-intense-fg ansi-bold">.</span>partitionBy<span class="ansi-yellow-intense-fg ansi-bold">(</span>partitionBy<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    843</span>         self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_set_opts<span class="ansi-yellow-intense-fg ansi-bold">(</span>compression<span class="ansi-yellow-intense-fg ansi-bold">=</span>compression<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 844</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_jwrite<span class="ansi-yellow-intense-fg ansi-bold">.</span>parquet<span class="ansi-yellow-intense-fg ansi-bold">(</span>path<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    845</span> 
<span class="ansi-green-fg">    846</span>     <span class="ansi-yellow-intense-fg ansi-bold">@</span>since<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-cyan-intense-fg ansi-bold">1.6</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\java_gateway.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-intense-fg ansi-bold">(self, *args)</span>
<span class="ansi-green-fg">   1255</span>         answer <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>gateway_client<span class="ansi-yellow-intense-fg ansi-bold">.</span>send_command<span class="ansi-yellow-intense-fg ansi-bold">(</span>command<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">   1256</span>         return_value = get_return_value(
<span class="ansi-green-intense-fg ansi-bold">-&gt; 1257</span><span class="ansi-yellow-intense-fg ansi-bold">             answer, self.gateway_client, self.target_id, self.name)
</span><span class="ansi-green-fg">   1258</span> 
<span class="ansi-green-fg">   1259</span>         <span class="ansi-green-intense-fg ansi-bold">for</span> temp_arg <span class="ansi-green-intense-fg ansi-bold">in</span> temp_args<span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\pyspark\sql\utils.py</span> in <span class="ansi-cyan-fg">deco</span><span class="ansi-blue-intense-fg ansi-bold">(*a, **kw)</span>
<span class="ansi-green-fg">     61</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> deco<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>a<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>kw<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">     62</span>         <span class="ansi-green-intense-fg ansi-bold">try</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">---&gt; 63</span><span class="ansi-yellow-intense-fg ansi-bold">             </span><span class="ansi-green-intense-fg ansi-bold">return</span> f<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">*</span>a<span class="ansi-yellow-intense-fg ansi-bold">,</span> <span class="ansi-yellow-intense-fg ansi-bold">**</span>kw<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     64</span>         <span class="ansi-green-intense-fg ansi-bold">except</span> py4j<span class="ansi-yellow-intense-fg ansi-bold">.</span>protocol<span class="ansi-yellow-intense-fg ansi-bold">.</span>Py4JJavaError <span class="ansi-green-intense-fg ansi-bold">as</span> e<span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">     65</span>             s <span class="ansi-yellow-intense-fg ansi-bold">=</span> e<span class="ansi-yellow-intense-fg ansi-bold">.</span>java_exception<span class="ansi-yellow-intense-fg ansi-bold">.</span>toString<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">C:\ieu\Anaconda3\envs\spark\lib\site-packages\py4j\protocol.py</span> in <span class="ansi-cyan-fg">get_return_value</span><span class="ansi-blue-intense-fg ansi-bold">(answer, gateway_client, target_id, name)</span>
<span class="ansi-green-fg">    326</span>                 raise Py4JJavaError(
<span class="ansi-green-fg">    327</span>                     <span class="ansi-blue-intense-fg ansi-bold">&#34;An error occurred while calling {0}{1}{2}.\n&#34;</span><span class="ansi-yellow-intense-fg ansi-bold">.</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 328</span><span class="ansi-yellow-intense-fg ansi-bold">                     format(target_id, &#34;.&#34;, name), value)
</span><span class="ansi-green-fg">    329</span>             <span class="ansi-green-intense-fg ansi-bold">else</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    330</span>                 raise Py4JError(

<span class="ansi-red-intense-fg ansi-bold">Py4JJavaError</span>: An error occurred while calling o250.parquet.
: org.apache.spark.SparkException: Job aborted.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:81)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)
	at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:566)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 29.0 failed 1 times, most recent failure: Lost task 4.0 in stage 29.0 (TID 68, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: ExitCodeException exitCode=-1073741502: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:866)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:849)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&lt;init&gt;(RawLocalFileSystem.java:225)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&lt;init&gt;(RawLocalFileSystem.java:209)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.&lt;init&gt;(ChecksumFileSystem.java:398)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)
	at org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)
	at org.apache.parquet.hadoop.ParquetFileWriter.&lt;init&gt;(ParquetFileWriter.java:248)
	at org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:390)
	at org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:349)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.&lt;init&gt;(ParquetOutputWriter.scala:37)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)
	at org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)
	at org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)
	... 10 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:167)
	... 33 more
Caused by: org.apache.spark.SparkException: Task failed while writing rows.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	... 1 more
Caused by: ExitCodeException exitCode=-1073741502: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582)
	at org.apache.hadoop.util.Shell.run(Shell.java:479)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:866)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:849)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&lt;init&gt;(RawLocalFileSystem.java:225)
	at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.&lt;init&gt;(RawLocalFileSystem.java:209)
	at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.&lt;init&gt;(ChecksumFileSystem.java:398)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)
	at org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)
	at org.apache.parquet.hadoop.ParquetFileWriter.&lt;init&gt;(ParquetFileWriter.java:248)
	at org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:390)
	at org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:349)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.&lt;init&gt;(ParquetOutputWriter.scala:37)
	at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)
	at org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)
	at org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)
	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)
	... 10 more
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

