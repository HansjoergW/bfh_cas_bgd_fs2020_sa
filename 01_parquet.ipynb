{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# stellt sicher, dass beim verÃ¤ndern der core library diese wieder neu geladen wird\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet\n",
    "Notebook to explore the basics of Parquet\n",
    "Links\n",
    "* Spark documentation https://spark.apache.org/docs/2.4.5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import os\n",
    "import zipfile\n",
    "from bfh_cas_bgd_fs2020_sa.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\n"
     ]
    }
   ],
   "source": [
    "# Check the current working dir\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Definition\n",
    "data_folder = \"./data/\" # folder with testdata\n",
    "temp_folder = \"./tmp/\"\n",
    "parquet_folder = \"./parquet/\"\n",
    "data_files = ['2019q3.zip','2019q4.zip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Spark\n",
    "> This code initialises the SparkSession and therefore the SparkContext. Pressing the link \"Spark UI\" opens the Spark UI for this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1145, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1149, in send_command\n",
      "    \"Error while sending\", e, proto.ERROR_ON_SEND)\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-6174a0f27226>\", line 2, in <module>\n",
      "    spark = get_spark_session() # Session anlegen\n",
      "  File \"C:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\", line 15, in get_spark_session\n",
      "    return SparkSession.builder.appName(appname).getOrCreate()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\", line 183, in getOrCreate\n",
      "    session._jsparkSession.sessionState().conf().setConfString(key, value)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1255, in __call__\n",
      "    answer = self.gateway_client.send_command(command)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1000, in send_command\n",
      "    response = self.send_command(command, binary=binary)\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 983, in send_command\n",
      "    connection = self._get_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 931, in _get_connection\n",
      "    connection = self._create_connection()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 937, in _create_connection\n",
      "    connection.start()\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1079, in start\n",
      "    raise Py4JNetworkError(msg, e)\n",
      "py4j.protocol.Py4JNetworkError: An error occurred while trying to connect to the Java server (127.0.0.1:62782)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'Py4JNetworkError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:62782)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1144\u001b[0m             \u001b[1;31m# if it sent a RST packet (SO_LINGER)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] Eine vorhandene Verbindung wurde vom Remotehost geschlossen",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1148\u001b[0m             raise Py4JNetworkError(\n\u001b[1;32m-> 1149\u001b[1;33m                 \"Error while sending\", e, proto.ERROR_ON_SEND)\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m: Error while sending",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Es konnte keine Verbindung hergestellt werden, da der Zielcomputer die Verbindung verweigerte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-6174a0f27226>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# init Spark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_spark_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Session anlegen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mspark\u001b[0m \u001b[1;31m# display the moste important information of the session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\projects\\bfh_cas_bgd_fs2020_sa\\bfh_cas_bgd_fs2020_sa\\core.py\u001b[0m in \u001b[0;36mget_spark_session\u001b[1;34m(appname)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \"\"\"\n\u001b[0;32m     14\u001b[0m     \u001b[0mfindspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msessionState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetConfString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpne\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Exception while sending command.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m                 \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m                 logging.exception(\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    981\u001b[0m          \u001b[1;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m         \"\"\"\n\u001b[1;32m--> 983\u001b[1;33m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[0;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[1;32m--> 937\u001b[1;33m         \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[1;34m\"server ({0}:{1})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:62782)"
     ]
    }
   ],
   "source": [
    "# init Spark\n",
    "spark = get_spark_session() # Session anlegen\n",
    "spark # display the moste important information of the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datafiles\n",
    "> The directory contains two zipfiles (2019q3.zip, 2019q4.zip). Each of them contains 4 csv files. The columns and the relation between these files are described in the readme.htm.\n",
    "> Each zip file contains all quarterly and yearly reports that were filled during the quarter denoted by the filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpacking\n",
    "> In a first step, the content of the files are unzipped and placed in separated folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_file in data_files:\n",
    "    path_to_zip_file = data_folder + data_file\n",
    "    directory_to_extract_to = temp_folder + data_file[:-4]\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the sizes of the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder:  76.58MB\n",
      "Temp folder:  748.04MB\n"
     ]
    }
   ],
   "source": [
    "print('Data folder: ', get_size_format(get_directory_size(data_folder)))\n",
    "print('Temp folder: ', get_size_format(get_directory_size(temp_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Parquet\n",
    "> let us read a csv file and store it as a parquet file\n",
    "> * API doc of the csv reader: https://spark.apache.org/docs/2.4.5/api/python/pyspark.sql.html?highlight=parquet#pyspark.sql.DataFrameReader.csv\n",
    "> * API doc of the parquet writer: https://spark.apache.org/docs/2.4.5/api/python/pyspark.sql.html?highlight=parquet#pyspark.sql.DataFrameWriter.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports that are used in this section\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of test file:  236.70MB\n"
     ]
    }
   ],
   "source": [
    "# as a test csv file, \"num.txt\" from the folder 2019q3 is used\n",
    "test_file = temp_folder + '2019q3/num.txt'\n",
    "print('size of test file: ', get_size_format(os.path.getsize(test_file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading a CSV file\n",
    "> As a first step, the csv file has to be loaded into a spark df. \n",
    "> The file has a header row and the columns are separated by a TAB (\\t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_num = spark.read.csv(test_file, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When checking the format in the next cell, we see that all columns were read as a string. That is ok for most of the columns but when checking the definitions for the num.txt file in the readme.htm we see, that ddate is a date in the format 'yyyymmdd', qtrs and coreg are 'int' and value is a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row:  [Row(adsh='0001625376-19-000017', tag='EntityPublicFloat', version='dei/2014', coreg=None, ddate=datetime.date(2018, 4, 30), qtrs=0, uom='USD', value=0.0, footnote=None)]\n",
      "count     : 2325267\n",
      "root\n",
      " |-- adsh: string (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      " |-- coreg: integer (nullable = true)\n",
      " |-- ddate: date (nullable = true)\n",
      " |-- qtrs: integer (nullable = true)\n",
      " |-- uom: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- footnote: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('first row: ', df_test_num.head(1))\n",
    "print('count     :', df_test_num.count())\n",
    "df_test_num.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Acutally, spark can try to infer the types of the columns from the data itself, so lets try that by using the \"inferSchema\" option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_num = spark.read.csv(test_file, sep='\\t', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As we can see in the next cell, we were only partially sucessfull. The reader was able to detect that qtrs is an integer and that value is a double. But it failed to recognize that ddate is actually a date and that coreg should be an int. That was to be expected: ddate looks like int and the coreg field is only used in special situations, so there is a good change that its field is None for all entries in the file. It looks as if we have to define the schema by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(adsh='0001625376-19-000017', tag='EntityPublicFloat', version='dei/2014', coreg=None, ddate=20180430, qtrs=0, uom='USD', value=0.0, footnote=None)]\n",
      "root\n",
      " |-- adsh: string (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      " |-- coreg: string (nullable = true)\n",
      " |-- ddate: integer (nullable = true)\n",
      " |-- qtrs: integer (nullable = true)\n",
      " |-- uom: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- footnote: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_test_num.head(1))\n",
    "df_test_num.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All necessary classes to define a schema are located inside the package pyspark.sql.types and for our example we need the following import\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, DoubleType, IntegerType\n",
    "\n",
    "> An important point is that the dateFormat has to be defined as parameter when calling spark.read.csv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"adsh\",    StringType(),  True),\\\n",
    "                     StructField(\"tag\",     StringType(),  True),\\\n",
    "                     StructField(\"version\", StringType(),  True),\\\n",
    "                     StructField(\"coreg\",   IntegerType(), True),\\\n",
    "                     StructField(\"ddate\",   DateType(),    True),\\\n",
    "                     StructField(\"qtrs\",    IntegerType(), True),\\\n",
    "                     StructField(\"uom\",     StringType(),  True),\\\n",
    "                     StructField(\"value\",   DoubleType(),  True),\\\n",
    "                     StructField(\"footnote\",StringType(),  True)\\\n",
    "                    ])\n",
    "df_test_num = spark.read.csv(test_file, sep='\\t', header=True, dateFormat=\"yyyyMMdd\", schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(adsh='0001625376-19-000017', tag='EntityPublicFloat', version='dei/2014', coreg=None, ddate=datetime.date(2018, 4, 30), qtrs=0, uom='USD', value=0.0, footnote=None)]\n",
      "root\n",
      " |-- adsh: string (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      " |-- coreg: integer (nullable = true)\n",
      " |-- ddate: date (nullable = true)\n",
      " |-- qtrs: integer (nullable = true)\n",
      " |-- uom: string (nullable = true)\n",
      " |-- value: double (nullable = true)\n",
      " |-- footnote: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_test_num.head(1))\n",
    "df_test_num.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple write as Parquet\n",
    "> As first version the dataframe is stored directly in parquet format without additional options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_folder_pure = parquet_folder+\"pure/\"\n",
    "df.write.parquet(parquet_folder_pure, mode=\"overwrite\") # mode 'overwrite' overwrites the data, if they are already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of parquet_folder_pure:  22.78MB\n"
     ]
    }
   ],
   "source": [
    "print('size of parquet_folder_pure: ', get_size_format(get_directory_size(parquet_folder_pure)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Parquet was able to compress the data down to 10% of the orginal size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using partitions\n",
    "> Parquet can also store the data in different partitions wich will create a new directory for every partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> in a first test we will partition by the \"adsh\" column which is the identifier for the different reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o250.parquet.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:81)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\r\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:566)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 29.0 failed 1 times, most recent failure: Lost task 4.0 in stage 29.0 (TID 68, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: ExitCodeException exitCode=-1073741502: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:582)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:479)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:866)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:849)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)\r\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:248)\r\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:390)\r\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:349)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:37)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)\r\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)\r\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)\r\n\t... 10 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:167)\r\n\t... 33 more\r\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: ExitCodeException exitCode=-1073741502: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:582)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:479)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:866)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:849)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)\r\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:248)\r\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:390)\r\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:349)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:37)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)\r\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)\r\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)\r\n\t... 10 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-33991c22aa44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparquet_folder_by_adsh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparquet_folder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"byadsh/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'adsh'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparquet_folder_by_adsh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"overwrite\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[1;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[0;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ieu\\Anaconda3\\envs\\spark\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o250.parquet.\n: org.apache.spark.SparkException: Job aborted.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:198)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:81)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\r\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\r\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:566)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 29.0 failed 1 times, most recent failure: Lost task 4.0 in stage 29.0 (TID 68, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: ExitCodeException exitCode=-1073741502: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:582)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:479)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:866)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:849)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)\r\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:248)\r\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:390)\r\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:349)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:37)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)\r\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)\r\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)\r\n\t... 10 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:167)\r\n\t... 33 more\r\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: ExitCodeException exitCode=-1073741502: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:582)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:479)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:866)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:849)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:733)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:225)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:209)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:307)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:296)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:328)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:398)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:461)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:440)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)\r\n\tat org.apache.hadoop.fs.FileSystem.create(FileSystem.java:892)\r\n\tat org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74)\r\n\tat org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:248)\r\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:390)\r\n\tat org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:349)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:37)\r\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:151)\r\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.newOutputWriter(FileFormatDataWriter.scala:236)\r\n\tat org.apache.spark.sql.execution.datasources.DynamicPartitionDataWriter.write(FileFormatDataWriter.scala:260)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:245)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)\r\n\t... 10 more\r\n"
     ]
    }
   ],
   "source": [
    "parquet_folder_by_adsh = parquet_folder+\"byadsh/\"\n",
    "df.write.partitionBy('adsh').parquet(parquet_folder_by_adsh, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
